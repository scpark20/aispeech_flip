{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02cc8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e7353b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataset import KSponSpeechDataset, DataCollate\n",
    "from torch.utils.data import DataLoader\n",
    "from jamo import n_symbols, text_to_tokens, tokens_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b10b69",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41539435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622545\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f06b4c0caf0>\n"
     ]
    }
   ],
   "source": [
    "dataset = KSponSpeechDataset(root_dir='/data/KsponSpeech')\n",
    "train_loader = DataLoader(dataset, num_workers=8, shuffle=True, batch_size=64, collate_fn=DataCollate())\n",
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d906c3",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f96dbe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, min_width=4):\n",
    "        super().__init__()\n",
    "        self.in_layer = nn.Sequential(nn.Conv1d(in_channels, hidden_channels, kernel_size=3, padding=1),\n",
    "                                      nn.BatchNorm1d(hidden_channels),\n",
    "                                      nn.ReLU())\n",
    "        self.lstm1 = nn.LSTM(hidden_channels, hidden_channels//2, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(hidden_channels*2, hidden_channels//2, batch_first=True, bidirectional=True)\n",
    "        self.lstm3 = nn.LSTM(hidden_channels*2, hidden_channels//2, batch_first=True, bidirectional=True)\n",
    "        self.out_layer = nn.Linear(hidden_channels, out_channels)\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.min_width = min_width\n",
    "        \n",
    "    def forward(self, x):\n",
    "        b, t, _ = x.size()\n",
    "        \n",
    "        pad_length = ((t - 1) // self.min_width + 1) * self.min_width - t\n",
    "        x = F.pad(x, (0, 0, 0, pad_length))\n",
    "        \n",
    "        # x : (batch, time, channel)\n",
    "        y = self.in_layer(x.transpose(1, 2)).transpose(1, 2)\n",
    "        \n",
    "        # (batch, time, channel)\n",
    "        y, _ = self.lstm1(y)\n",
    "        # (batch, time/2, channel)\n",
    "        y = y.reshape(b, y.size(1)//2, self.hidden_channels*2)\n",
    "        \n",
    "        # (batch, time/2, channel)\n",
    "        y, _ = self.lstm2(y)\n",
    "        # (batch, time/4, channel)\n",
    "        y = y.reshape(b, y.size(1)//2, self.hidden_channels*2)\n",
    "        \n",
    "        # (batch, time/4, channel)\n",
    "        y, _ = self.lstm3(y)\n",
    "        y = self.out_layer(y)\n",
    "        \n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad21823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_symbols, embedding_channels, hidden_channels, encoded_channels):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(n_symbols, embedding_channels)\n",
    "        self.in_layer = nn.Sequential(nn.Linear(embedding_channels, hidden_channels),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lstm1 = nn.LSTMCell(hidden_channels, hidden_channels)\n",
    "        self.lstm2 = nn.LSTMCell(hidden_channels+encoded_channels, hidden_channels)\n",
    "        self.out_layer = nn.Linear(hidden_channels, n_symbols)\n",
    "        self.W = nn.Parameter(torch.randn(1, hidden_channels, encoded_channels))\n",
    "        self.encoded_channels = encoded_channels\n",
    "    \n",
    "    def _get_attention_context(self, s, h):\n",
    "        # s : (batch, hidden)\n",
    "        # h : (batch, length, encoded)\n",
    "        \n",
    "        # (batch, 1, length) = (batch, 1, hidden) @ (1, hidden, encoded) @ (batch, encoded, length)\n",
    "        score = s.unsqueeze(1) @ self.W @ h.transpose(1, 2)\n",
    "        score = score / np.sqrt(self.encoded_channels)\n",
    "        # (batch, 1, length)\n",
    "        weight = score.softmax(dim=2)\n",
    "        # (batch, 1, encoded)\n",
    "        context = weight @ h\n",
    "        \n",
    "        # (batch, encoded)\n",
    "        return context[:, 0], weight[:, 0]\n",
    "        \n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        # x : (batch, time, channel)\n",
    "        # h : (batch, length, channel)\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.in_layer(x)\n",
    "        state1 = None # (hidden, cell)\n",
    "        state2 = None # (hidden, cell)\n",
    "        outputs = []\n",
    "        alignments = []\n",
    "        for t in range(x.size(1)):\n",
    "            # (hidden, cell)\n",
    "            state1 = self.lstm1(x[:, t], state1)\n",
    "            # (batch, encoded)\n",
    "            context, weight = self._get_attention_context(state1[0], h)\n",
    "            alignments.append(weight)\n",
    "            # (hidden, cell)\n",
    "            state2 = self.lstm2(torch.cat([state1[0], context], dim=1), state2)\n",
    "            outputs.append(state2[0])\n",
    "            \n",
    "        # (batch, time, channel)\n",
    "        outputs = torch.stack(outputs, dim=1)\n",
    "        # (batch, length, time)\n",
    "        alignments = torch.stack(alignments, dim=2)\n",
    "        x = self.out_layer(outputs)\n",
    "        \n",
    "        return x, alignments\n",
    "    \n",
    "    def inference(self, h):\n",
    "        # h : (1, length, channel)\n",
    "        tokens = torch.zeros(size=(1, 1)).long().to(h.device)\n",
    "        \n",
    "        state1 = None\n",
    "        state2 = None\n",
    "        alignments = []\n",
    "        logprob = 0\n",
    "        for _ in range(1000):\n",
    "            x = tokens[:, -1]\n",
    "            x = self.embedding(x)\n",
    "            x = self.in_layer(x)\n",
    "            state1 = self.lstm1(x, state1)\n",
    "            context, weight = self._get_attention_context(state1[0], h)\n",
    "            alignments.append(weight)\n",
    "            state2 = self.lstm2(torch.cat([state1[0], context], dim=1), state2)\n",
    "            logit = self.out_layer(state2[0])\n",
    "            token = torch.distributions.categorical.Categorical(logits=logit).sample().to(h.device)\n",
    "            logprob += logit.log_softmax(dim=1)[0, token[0].item()].item()\n",
    "            tokens = torch.cat([tokens, token.unsqueeze(0)], dim=1)\n",
    "            if token[0].item() == 0:\n",
    "                break\n",
    "            \n",
    "        alignments = torch.stack(alignments, dim=2)\n",
    "            \n",
    "        return tokens, alignments, logprob\n",
    "    \n",
    "    def beam_search(self, h, beam_size=10):\n",
    "        tokens = torch.zeros(size=(1, 1)).long().to(h.device)\n",
    "        \n",
    "        # (tokens, state1, state2, alignments, log_prob, end)\n",
    "        beam_list = [(tokens, None, None, [], 0, False)]\n",
    "        beam_lists = []\n",
    "        for _ in range(1000):\n",
    "            new_beam_list = []\n",
    "            beam_lists.append(beam_list)\n",
    "            for beam in beam_list:\n",
    "                tokens, state1, state2, alignments, log_prob, end = beam\n",
    "                if end:\n",
    "                    new_beam_list.append(beam)\n",
    "                    continue\n",
    "                    \n",
    "                x = tokens[:, -1]\n",
    "                x = self.embedding(x)\n",
    "                x = self.in_layer(x)\n",
    "                state1 = self.lstm1(x, state1)\n",
    "                context, weight = self._get_attention_context(state1[0], h)\n",
    "                alignments.append(weight)\n",
    "                state2 = self.lstm2(torch.cat([state1[0], context], dim=1), state2)\n",
    "                # (1, n_symbols)\n",
    "                logits = self.out_layer(state2[0])\n",
    "                # (1, n_symbols)\n",
    "                new_log_probs = logits.log_softmax(dim=1)\n",
    "                # (1, beam_size), (1, beam_size)\n",
    "                new_log_probs, indexes = new_log_probs.topk(beam_size, dim=1)\n",
    "                for i in range(new_log_probs.size(1)):\n",
    "                    new_tokens = torch.cat([tokens, indexes[:, i:i+1]], dim=1)\n",
    "                    new_log_prob = log_prob + new_log_probs[0, i].item()\n",
    "                    if indexes[0, i].item() == 0:\n",
    "                        end = True\n",
    "                    new_beam_list.append((new_tokens, state1, state2, alignments, new_log_prob, end))\n",
    "            \n",
    "            new_beam_list = sorted(new_beam_list, key=lambda x:x[4] / x[0].size(1), reverse=True)\n",
    "            beam_list = new_beam_list[:beam_size]\n",
    "            \n",
    "            all_end = True\n",
    "            for beam in beam_list:\n",
    "                all_end = all_end and beam[5]\n",
    "            if all_end:\n",
    "                break\n",
    "        \n",
    "        return beam_list, beam_lists\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc560f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LAS(nn.Module):\n",
    "    def __init__(self, mel_channels, \n",
    "                       encoder_hidden_channels,\n",
    "                       encoder_output_channels,\n",
    "                       n_symbols,\n",
    "                       embedding_channels,\n",
    "                       decoder_hidden_channels):\n",
    "                      \n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(mel_channels, encoder_hidden_channels, encoder_output_channels)\n",
    "        self.decoder = Decoder(n_symbols, embedding_channels, decoder_hidden_channels, encoder_output_channels)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # x : (batch, time, mel_channels)\n",
    "        # y : (batch, length)\n",
    "        \n",
    "        h = self.encoder(x)\n",
    "        out, alignments = self.decoder(y, h)\n",
    "        \n",
    "        return out, alignments\n",
    "    \n",
    "    def inference(self, x):\n",
    "        # x : (batch, time, mel_channels)\n",
    "        h = self.encoder(x)\n",
    "        out, alignments, logprob = self.decoder.inference(h)\n",
    "        \n",
    "        return out, alignments, logprob\n",
    "    \n",
    "    def beam_search(self, x, beam_size=10):\n",
    "        # x : (batch, time, mel_channels)\n",
    "        h = self.encoder(x)\n",
    "        beam_list, beam_lists = self.decoder.beam_search(h, beam_size=beam_size)\n",
    "        \n",
    "        return beam_list, beam_lists\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e522f",
   "metadata": {},
   "source": [
    "### Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146f85ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import sizeof_fmt, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec22f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘save’: File exists\n",
      "<utils.Logger object at 0x7f069eef78e0>\n"
     ]
    }
   ],
   "source": [
    "!mkdir save\n",
    "save_dir = 'save/las_lstm_kspon'\n",
    "logger = Logger(save_dir=save_dir, new=False)\n",
    "print(logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fbb7d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_0\t    save_15000\tsave_25000  save_30711\r\n",
      "save_10000  save_20000\tsave_30000  save_5000\r\n"
     ]
    }
   ],
   "source": [
    "!ls $save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e081a26",
   "metadata": {},
   "source": [
    "### Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591e9e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size 51.8MiB\n",
      "loaded : 30711\n",
      "loaded 30711\n"
     ]
    }
   ],
   "source": [
    "model = LAS(mel_channels=80, \n",
    "           encoder_hidden_channels=512,\n",
    "           encoder_output_channels=512,\n",
    "           n_symbols=n_symbols,\n",
    "           embedding_channels=512,\n",
    "           decoder_hidden_channels=512)\n",
    "\n",
    "model = model.cuda()\n",
    "step = 30711\n",
    "\n",
    "size = sizeof_fmt(4 * sum(p.numel() for p in model.parameters()))\n",
    "print(f\"Model size {size}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "if True:\n",
    "    model, optimizer, step = logger.load(step, model, optimizer)\n",
    "    print('loaded', step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c910568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_cuda(batch):\n",
    "    batch['audio'] = batch['audio'].cuda()\n",
    "    batch['audio_lengths'] = batch['audio_lengths'].cuda()\n",
    "    batch['text'] = F.pad(batch['text'].cuda(), (1, 1))\n",
    "    batch['text_lengths'] = batch['text_lengths'].cuda() + 2\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e69e9b7",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8405c4d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth : \u0000오 대박이다. 나도 스위스 간 적 있거든?\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\n",
      "beam search\n",
      "\u0000오 대박이다. 나도 스에스 간 적이 있거든?\u0000 -5.331748947733786\n",
      "\u0000오 대박이다. 나도 스에스 간적이 있거든?\u0000 -5.273309580356198\n",
      "\u0000오 대박이다. 나도 스위스 간적이 있거든?\u0000 -5.474907666925191\n",
      "\u0000오 대박이다. 나도 스에스 간 적이 있거든.\u0000 -5.698828134452697\n",
      "\u0000오 대박이다. 나도 스에스 간적이 있거든.\u0000 -5.645561967583689\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stop = True\n",
    "while True:\n",
    "    for batch in train_loader:\n",
    "        batch = to_cuda(batch)\n",
    "        model.train()\n",
    "        model.zero_grad()\n",
    "        logits, alignments = model(batch['audio'], batch['text'])\n",
    "        loss = nn.CrossEntropyLoss()(logits[:, :-1].transpose(1, 2), batch['text'][:, 1:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(step, loss.item())\n",
    "        \n",
    "        if step % 5000 == 0:\n",
    "            logger.save(step, model, optimizer)\n",
    "            \n",
    "        if step % 100 == 0:\n",
    "            display.clear_output()\n",
    "            \n",
    "            _alignment = alignments.data.cpu().numpy()\n",
    "            plt.figure(figsize=[18, 3])\n",
    "            plt.title('Attention Alignments')\n",
    "            for i in range(3):\n",
    "                plt.subplot(1, 3, i+1)\n",
    "                plt.imshow(_alignment[i].T, aspect='auto', origin='lower', interpolation='none')\n",
    "            plt.show()\n",
    "            \n",
    "            text = tokens_to_text(batch['text'][0].data.cpu().numpy())\n",
    "            print('ground truth :', text)\n",
    "            \n",
    "            print('beam search')\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                beam_list, beam_lists = model.beam_search(batch['audio'][0:1], beam_size=5)\n",
    "                for beam in beam_list:\n",
    "                    text = tokens_to_text(beam[0][0].data.cpu().numpy())\n",
    "                    score = beam[4]\n",
    "                    print(text, score)\n",
    "                    \n",
    "            if stop:\n",
    "                break\n",
    "                \n",
    "        step += 1\n",
    "        \n",
    "    if stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c5245ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved save/las_lstm_kspon/save_30711\n"
     ]
    }
   ],
   "source": [
    "logger.save(step, model, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
